{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown\n!gdown https://drive.google.com/uc?id=1ImRFKG1QyNahvUh9en-lwK6NcJTqPUsm\n!tar -zxf /kaggle/working/GAIIC2024-ËµõÈÅì1-ÁõÆÊ†áÊ£ÄÊµã‰ªªÂä°.tar.gz\n\n!python /kaggle/working/obj-detection/coco2yolo_train.py\n!python /kaggle/working/obj-detection/coco2yolo_val.py\n\n!python /kaggle/working/obj-detection/jpg2webp.py\n\n!pip install -r /kaggle/working/obj-detection/yolov9/requirements.txt","metadata":{"_uuid":"7bdf1f99-e1cc-474d-969d-812898455562","_cell_guid":"80bb177f-9691-4f00-9b44-2e4d177c7d52","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/obj-detection*\n!git clone https://github.com/LRC-bit/obj-detection.git    #ÊãâÂèñÊúÄÊñ∞ÁöÑobj-detection‰ª£Á†Å","metadata":{"execution":{"iopub.status.busy":"2024-05-03T03:52:05.659300Z","iopub.execute_input":"2024-05-03T03:52:05.659875Z","iopub.status.idle":"2024-05-03T03:52:08.254248Z","shell.execute_reply.started":"2024-05-03T03:52:05.659808Z","shell.execute_reply":"2024-05-03T03:52:08.252632Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Cloning into 'obj-detection'...\nremote: Enumerating objects: 270, done.\u001b[K\nremote: Counting objects: 100% (195/195), done.\u001b[K\nremote: Compressing objects: 100% (96/96), done.\u001b[K\nremote: Total 270 (delta 106), reused 174 (delta 96), pack-reused 75\u001b[K\nReceiving objects: 100% (270/270), 286.94 KiB | 11.96 MiB/s, done.\nResolving deltas: 100% (125/125), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!python /kaggle/working/obj-detection/yolov9/train_dual.py --batch-size=8 --hyp=/kaggle/working/obj-detection/yolov9/hyp.yaml --data=/kaggle/working/obj-detection/data.yaml --cfg=/kaggle/working/obj-detection/yolov9/models/detect/yolov9.yaml","metadata":{"execution":{"iopub.status.busy":"2024-05-03T03:52:10.534653Z","iopub.execute_input":"2024-05-03T03:52:10.535182Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"2024-05-03 03:52:23.168681: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-03 03:52:23.168925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-03 03:52:23.369152: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=, cfg=/kaggle/working/obj-detection/yolov9/models/detect/yolov9.yaml, data=/kaggle/working/obj-detection/data.yaml, hyp=/kaggle/working/obj-detection/yolov9/hyp.yaml, epochs=100, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=obj-detection/yolov9/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\nYOLO üöÄ 2024-5-3 Python-3.10.13 torch-2.1.2+cpu CPU\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0.1, scale=0.3, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO üöÄ in ClearML\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO üöÄ runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir obj-detection/yolov9/runs/train', view at http://localhost:6006/\nDownloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 22.1MB/s]\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1         0  models.common.Silence                   []                            \n  1                -1  1      2432  models.common.Conv                      [4, 64, 3, 2]                 \n  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  3                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n  4                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n  5                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n  6                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n  7                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n  8                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n  9                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n 10                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 7]  1         0  models.common.Concat                    [1]                           \n 13                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 15           [-1, 5]  1         0  models.common.Concat                    [1]                           \n 16                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n 17                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 18          [-1, 13]  1         0  models.common.Concat                    [1]                           \n 19                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n 20                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n 21          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 22                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n 23                 5  1    131328  models.common.CBLinear                  [512, [256]]                  \n 24                 7  1    393984  models.common.CBLinear                  [512, [256, 512]]             \n 25                 9  1    656640  models.common.CBLinear                  [512, [256, 512, 512]]        \n 26                 0  1      2432  models.common.Conv                      [4, 64, 3, 2]                 \n 27                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n 28                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n 29                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 30  [23, 24, 25, -1]  1         0  models.common.CBFuse                    [[0, 0, 0]]                   \n 31                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n 32                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n 33      [24, 25, -1]  1         0  models.common.CBFuse                    [[1, 1]]                      \n 34                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n 35                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n 36          [25, -1]  1         0  models.common.CBFuse                    [[2]]                         \n 37                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n 38[31, 34, 37, 16, 19, 22]  1  21552062  models.yolo.DualDDetect                 [5, [512, 512, 512, 256, 512, 512]]\nyolov9 summary: 930 layers, 60807614 parameters, 60807582 gradients\n\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 230 weight(decay=0.0), 247 weight(decay=0.0005), 245 bias\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 17957 images, 33 backgrou\u001b[0m\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1467 images, 2 backgrounds, 0\u001b[0m\nPlotting labels to obj-detection/yolov9/runs/train/exp/labels.jpg... \n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mobj-detection/yolov9/runs/train/exp\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       0/99         0G      7.042      5.859      5.314        171        640:  WARNING ‚ö†Ô∏è TensorBoard graph visualization failure Given groups=1, weight of size [64, 4, 3, 3], expected input[1, 3, 640, 640] to have 4 channels, but got 3 channels instead\n       0/99         0G      6.898      5.845      5.332        261        640:  ","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf /kaggle/working/obj-detection/yolov9/runs*    #Âà†Èô§Êñá‰ª∂Êó∂‰ΩøÁî®","metadata":{"execution":{"iopub.status.busy":"2024-05-02T15:10:46.198395Z","iopub.execute_input":"2024-05-02T15:10:46.198716Z","iopub.status.idle":"2024-05-02T15:10:47.204641Z","shell.execute_reply.started":"2024-05-02T15:10:46.198684Z","shell.execute_reply":"2024-05-02T15:10:47.203161Z"},"trusted":true},"execution_count":39,"outputs":[]}]}